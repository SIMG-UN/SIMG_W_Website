---
title: "Lecture 1 - GPU Programming Model, Architecture and Memory Layout"
description: "An in-depth introduction to GPU programming fundamentals: the CUDA programming model, GPU hardware architecture (SMs, warps, threads), and memory hierarchy (global, shared, local, constant, texture). Learn how data flows between CPU and GPU and how to reason about kernel launches."
date: 2026-02-27
time: "6:30 PM - 9:00 PM"
speaker: "SIMG Research Group"
eventType: "virtual"
meetingLink: "https://meet.google.com/tbd"
meetingPlatform: "meet"
googleCalendarLink: "https://calendar.google.com/calendar/render?action=TEMPLATE&text=Lecture+1+-+GPU+Programming+Model&dates=20260227T233000Z/20260228T020000Z&details=In-depth+introduction+to+GPU+programming+fundamentals&location=https://meet.google.com/tbd&sf=true&output=xml"
recurrent: false
thumbnail: "/images/events/gpu-programming-model.svg"
tags: ["CUDA", "GPU", "Architecture", "Memory Layout", "HPC"]
status: "upcoming"
lang: "en"
translationKey: "gpu-programming-model"
participants: []
duration: "2h 30m"
---

## Overview

This lecture covers the foundational concepts of GPU programming. We will explore the CUDA programming model, understand GPU hardware architecture including Streaming Multiprocessors (SMs), warps, and thread hierarchies, and dive deep into the GPU memory layout.

### Topics

- **CUDA Programming Model**: Kernels, grids, blocks, and threads
- **GPU Architecture**: SMs, CUDA cores, warp scheduling
- **Memory Hierarchy**: Global, shared, local, constant, and texture memory
- **Host-Device Data Transfer**: `cudaMemcpy`, pinned memory, async transfers
- **Kernel Launch Configuration**: Choosing grid and block dimensions

### Prerequisites

- Basic understanding of C/C++ or Python
- Familiarity with parallel computing concepts (helpful but not required)

### What to Bring

- Laptop with CUDA-capable GPU (optional â€” we'll have cloud environments available)
- Curiosity about high-performance computing!
